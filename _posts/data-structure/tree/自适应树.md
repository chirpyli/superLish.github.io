我们知道常见的树有二叉查找树、AVL树、红黑树，AVL树与红黑树都是为了解决二叉查找树可能存在的平衡行问题，让树在插入、删除节点时能使树做到一定的自平衡。但平衡不是目的，最终的目的是加快查找、插入、删除等操作的效率，AVL树与红黑树是通过使二叉树尽量平衡从而加快各种操作的效率，但是是不是唯一的方法呢？

答案是不是的，如同自适应链表一样，同样，树也可以通过自适应树加快查找、插入、删除等的效率。实际应用中，并非所有元素的使用频率都相同，我们可以把使用频率高的元素上移到靠近树根的地方，使用频率低的元素就沉到树底部了，最后，使用频率高的元素分布在树的顶部，这样，一定程度上同样能实现各种操作效率的提高。AVL树为了提高效率，插入与删除时旋转操作比较多，而红黑树平衡性的要求降低了一点，但依然有大量的旋转及颜色变换操作。自适应树虽然平衡性上最差，但其因维护平衡性而做的额外操作也最少，其性能的提高，不单依赖自适应树的实现，很大程度上还依赖所操作的元素的概率统计特性，如果每个元素使用频率都差不多，那性能可能提升不是很明显，且大概率上比红黑树效率低，但如果各个元素的使用频率服从一定的概率分布（如少量高频元素，大量低频元素），那效率的提升会较为明显，性能可能会比红黑树高。

具体什么实现自适应树呢？有多种实现。

### 自重新构造树
类比自组织链表的前移法和换位法，有两种方式：
- 单一旋转：如果访问子节点中的元素，则将子节点围绕它的父节点进行旋转，根节点除外。（相当于换位法）
- 移动到根部：重复子节点-父节点的旋转，直到被访问的元素位于根部为止。（相当于前移法）
无论是单一旋转还是移动到根部，其出发点都是高频节点，最近访问的节点放到树的顶部，类似计算机中的局部性原理，另外其具体实现都是通过旋转操作，因为二叉树与链表不同，须使用旋转操作才能保持二叉查找树的性质。

>单一旋转代码实现参考[selftree.h](./selftree.h)

### "张开"策略（splaying）
移动到根部的一个修改版本称为“张开”策略，使用该策略实现的树也叫伸展树。该策略根据子节点、父节点和祖父节点之间链接关系的顺序，成对的使用单一旋转。根据被访问节点R、其父节点Q及其祖父节点P之间的关系，分为三种情况：
- case1： 节点R的父节点Q是根节点。
- case2： 同构配置。即R是Q的左子节点，Q是P的左子节点，或镜像对称的情况。
- case3： 异构配置。即R是Q的右子节点，Q是P的左子节点，或镜像对称的情况。

算法描述如下：
```
splaying(P, Q, T)
    while R不是根节点
        if case1
            进行单一张开操作，R围绕父节点Q旋转
        if case2
            进行一次同构张开操作，首先Q围绕P旋转，再R围绕Q旋转
        if case3
            进行一次异构张开操作，首先R围绕Q旋转，再R围绕P旋转
```

该策略相比简单的移动到根部的做法的好处是，在移动元素的同时兼顾了树的平衡性，但这种平衡性相比AVL树、红黑树比较脆弱，AVL有平衡因子的限制，红黑树也有平衡性的下限，但伸展树它的平衡性很脆弱，其下限是最糟糕的情况，有可能将树退化为链表。所以伸展树的优缺点都很明显，优点是简单，缺点是性能下限很低，性能好坏依赖所操作元的的概率统计特性。

下面简单描述一下实现插入、查找、删除的实现思路：
**插入：** 插入操作比较简单，按二叉查找树的插入方法插入新节点后，伸展该节点到根节点。
**查找：** 查找与插入类似，找到该节点后，伸展该节点到根节点。
**删除：** 删除稍微麻烦一点，有两个操作方法。方法一，如果被删除的节点没有子节点或只有一个子节点，直接删掉该节点然后伸展被删除节点的父节点，否则，先进行复制删除，然后伸展被复制的节点；方法二，先旋转被删除的节点到根节点，删除根节点，变成左右2个子树，再将左右两个子树进行拼接。
>拼接方法，这里因为是删除根节点后的左右两个子树，有左子树的所有节点都小于右子树，找到左子树的最大节点，伸展至左子树根节点，将右子树拼接至左子树最大值节点的右子树。


>代码实现参考[selftree.h](./selftree.h)

>参考文档：
[Splay tree](https://en.wikipedia.org/wiki/Splay_tree)